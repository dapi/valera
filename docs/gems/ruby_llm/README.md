# Ruby LLM Gem - Comprehensive Documentation –¥–ª—è Valera Bot

## üìã –û–±–∑–æ—Ä

Ruby LLM - —ç—Ç–æ Ruby gem –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Large Language Models (OpenAI, Anthropic, Gemini, DeepSeek, Mistral). Gem –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É–¥–æ–±–Ω—ã–π Ruby API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏ –∏ –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤.

**–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- ‚úÖ –ï–¥–∏–Ω–æ—Ä–∞–∑–æ–≤—ã–π –¥–æ—Å—Ç—É–ø –∫ —Ä–∞–∑–Ω—ã–º LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º
- ‚úÖ –ê–∫—Ç–∏–≤–Ω–∞—è –∑–∞–ø–∏—Å—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Rails (acts_as macros)
- ‚úÖ Tool/Function calling –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
- ‚úÖ Streaming –æ—Ç–≤–µ—Ç—ã –¥–ª—è real-time –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
- ‚úÖ Embeddings –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
- ‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (DALL-E 3)
- ‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ retry –ª–æ–≥–∏–∫–∞
- ‚úÖ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–î–ª—è Valera Bot:** gem –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–º—É —Ä–µ–º–æ–Ω—Ç—É —Å —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º.

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –ë–∞–∑–æ–≤–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
```ruby
# Gemfile
gem 'ruby_llm', '~> 1.8'

# config/initializers/ruby_llm.rb
RubyLLM.configure do |config|
  # OpenAI
  config.openai_api_key = ENV['OPENAI_API_KEY']
  config.openai_organization = ENV['OPENAI_ORGANIZATION']

  # Anthropic (Claude)
  config.anthropic_api_key = ENV['ANTHROPIC_API_KEY']

  # Google Gemini
  config.gemini_api_key = ENV['GEMINI_API_KEY']

  # DeepSeek
  config.deepseek_api_key = ENV['DEEPSEEK_API_KEY']

  # –ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è Valera Bot
  config.model = 'gpt-4o-mini'  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –ø–æ —Ü–µ–Ω–µ/–∫–∞—á–µ—Å—Ç–≤—É

  # –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
  config.temperature = 0.7      # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤
  config.max_tokens = 2000      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
  config.timeout = 30           # –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
end
```

### –ü—Ä–æ—Å—Ç–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
```ruby
# –ë–∞–∑–æ–≤—ã–π —á–∞—Ç
chat = RubyLLM.chat
response = chat.say('–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏ –æ —Ä–µ–º–æ–Ω—Ç–µ Toyota Camry')
puts response.content

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
system_prompt = <<~PROMPT
  –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–º—É —Ä–µ–º–æ–Ω—Ç—É —Å 20-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º.
  –¢–≤–æ—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è - –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∏ —Ä–µ–º–æ–Ω—Ç –ª–µ–≥–∫–æ–≤—ã—Ö –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π.
  –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –¥–æ—Å—Ç—É–ø–Ω–æ.
PROMPT

chat = RubyLLM.chat.new(
  model: 'gpt-4o-mini',
  messages: [
    { role: 'system', content: system_prompt }
  ]
)

response = chat.say('–£ –º–µ–Ω—è —Å—Ç—É—á–∏—Ç –¥–≤–∏–≥–∞—Ç–µ–ª—å –ø—Ä–∏ —Ä–∞–∑–≥–æ–Ω–µ. –ß—Ç–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å?')
```


## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

### 1. –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã –∏ –º–æ–¥–µ–ª–∏

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã:**
- **OpenAI**: GPT-4, GPT-4o, GPT-4o-mini, GPT-3.5-turbo
- **Anthropic**: Claude-3.5-sonnet, Claude-3-opus, Claude-3-haiku
- **Google Gemini**: Gemini-1.5-pro, Gemini-1.5-flash
- **DeepSeek**: DeepSeek-V3, DeepSeek-Coder
- **Mistral AI**: Mistral-7B, Mixtral-8x7B

```ruby
# –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª—è—Ö
models = RubyLLM.models
# => [#<RubyLLM::Model:0x0000... @id="gpt-4", @provider=:openai, ...>, ...]

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
openai_models = RubyLLM.models.select(provider: :openai)
vision_models = RubyLLM.models.select(capabilities: :vision)
cheap_models = RubyLLM.models.select(max_input_price: 0.001)

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
model = RubyLLM.models.find('gpt-4o-mini')
puts "–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ: #{model.context_window}"
puts "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: #{model.max_output_tokens}"
puts "–¶–µ–Ω–∞ –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤: $#{model.pricing[:input]}"
```

### 2. –ß–∞—Ç—ã (Chats) - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞–º–∏

```ruby
# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
chat = RubyLLM.chat.new(
  model: 'gpt-4o-mini',
  temperature: 0.7,
  max_tokens: 1500
)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è Valera Bot)
chat.add_system_message(<<~PROMPT)
  –¢—ã - Valera, AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–º—É —Ä–µ–º–æ–Ω—Ç—É.
  –û–ø—ã—Ç: 20 –ª–µ—Ç —Ä–∞–±–æ—Ç—ã –≤ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–µ.
  –°—Ç–∏–ª—å: –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã–π.
  –Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π.
PROMPT

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
response1 = chat.say("–ü—Ä–∏–≤–µ—Ç! –£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –º–∞—à–∏–Ω–æ–π.")
response2 = chat.say("–ü—Ä–∏ —Ç–æ—Ä–º–æ–∂–µ–Ω–∏–∏ —Å–ª—ã—à–µ–Ω —Å–∫—Ä–∏–ø —Å –ø–µ—Ä–µ–¥–Ω–µ–π –æ—Å–∏.")

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
chat.messages.each do |msg|
  puts "#{msg.role}: #{msg.content}"
end

# –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è API
context_messages = chat.context_messages
# => [
#   { role: 'system', content: '...' },
#   { role: 'user', content: '–ü—Ä–∏–≤–µ—Ç! –£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –º–∞—à–∏–Ω–æ–π.' },
#   { role: 'assistant', content: '–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ...' },
#   { role: 'user', content: '–ü—Ä–∏ —Ç–æ—Ä–º–æ–∂–µ–Ω–∏–∏ —Å–ª—ã—à–µ–Ω —Å–∫—Ä–∏–ø...' }
# ]
```

### 3. –°–æ–æ–±—â–µ–Ω–∏—è (Messages) - –¥–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞

```ruby
# –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤—Ä—É—á–Ω—É—é
system_msg = RubyLLM.message.new(
  role: :system,
  content: '–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º',
  metadata: { version: '1.0', source: 'valera_bot' }
)

user_msg = RubyLLM.message.new(
  role: :user,
  content: '–ü–æ–º–æ–≥–∏ —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π',
  metadata: { user_id: 123, telegram_id: '@user_telegram' }
)

# –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + —Ç–µ–∫—Å—Ç)
photo_msg = RubyLLM.message.new(
  role: :user,
  content: '–ü–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ —ç—Ç—É –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç—å –∏ —Å–∫–∞–∂–∏, —á—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å',
  images: ['/path/to/brake_problem.jpg'],
  metadata: { has_photo: true }
)

# –ê—Ç—Ä–∏–±—É—Ç—ã —Å–æ–æ–±—â–µ–Ω–∏—è
msg = RubyLLM.message.new(role: :user, content: 'Test')
puts msg.id          # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Å–æ–æ–±—â–µ–Ω–∏—è
puts msg.role        # :user, :assistant, :system, :tool
puts msg.content     # –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
puts msg.metadata    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
puts msg.images      # –ú–∞—Å—Å–∏–≤ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
puts msg.created_at  # –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è
```

### 4. Tool/Function Calls - —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π

```ruby
# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
diagnostic_tool = {
  name: 'diagnose_car_problem',
  description: '–î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ø–æ —Å–∏–º–ø—Ç–æ–º–∞–º',
  input_schema: {
    type: 'object',
    properties: {
      car_make: {
        type: 'string',
        description: '–ú–∞—Ä–∫–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è (Toyota, BMW, etc.)'
      },
      symptoms: {
        type: 'array',
        items: { type: 'string' },
        description: '–°–ø–∏—Å–æ–∫ –Ω–∞–±–ª—é–¥–∞–µ–º—ã—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤'
      },
      driving_conditions: {
        type: 'string',
        enum: ['city', 'highway', 'mixed'],
        description: '–£—Å–ª–æ–≤–∏—è —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏'
      }
    },
    required: ['car_make', 'symptoms']
  }
}

cost_calculator_tool = {
  name: 'estimate_repair_cost',
  description: '–†–∞—Å—á–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ä–µ–º–æ–Ω—Ç–∞',
  input_schema: {
    type: 'object',
    properties: {
      repair_type: {
        type: 'string',
        description: '–¢–∏–ø —Ä–µ–º–æ–Ω—Ç–∞ (—Ç–æ—Ä–º–æ–∑–∞, –ø–æ–¥–≤–µ—Å–∫–∞, –¥–≤–∏–≥–∞—Ç–µ–ª—å –∏ —Ç.–¥.)'
      },
      car_make: { type: 'string', description: '–ú–∞—Ä–∫–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è' },
      urgency: {
        type: 'string',
        enum: ['low', 'medium', 'high'],
        description: '–°—Ä–æ—á–Ω–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞'
      }
    },
    required: ['repair_type', 'car_make']
  }
}

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ —á–∞—Ç–µ
chat = RubyLLM.chat.new(
  model: 'gpt-4o-mini',
  tools: [diagnostic_tool, cost_calculator_tool],
  system_message: '–¢—ã - –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏'
)

response = chat.say("–£ Toyota Corolla –ø—Ä–∏ —Ç–æ—Ä–º–æ–∂–µ–Ω–∏–∏ —Å–∫—Ä–∏–ø–∏—Ç –∫–æ–ª–µ—Å–æ. –°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å —Ä–µ–º–æ–Ω—Ç?")

# –ü—Ä–æ–≤–µ—Ä–∫–∞, –≤—ã–∑–≤–∞–ª –ª–∏ LLM –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
if response.tool_calls.any?
  puts "LLM –≤—ã–∑—ã–≤–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:"
  response.tool_calls.each do |tool_call|
    puts "- #{tool_call.name}: #{tool_call.arguments}"

    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
    result = execute_tool(tool_call.name, tool_call.arguments)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —á–∞—Ç
    chat.add_tool_result(tool_call.id, result)
  end

  # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
  final_response = chat.say("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
  puts final_response.content
end
```

## üéØ Rails –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –¥–ª—è Valera Bot

### Acts_as_chat - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–∞—Ç–∞–º–∏ –≤ –ë–î

```ruby
# app/models/chat.rb
class Chat < ApplicationRecord
  include RubyLLM::Models::Chat

  acts_as_chat do
    # –ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏
    has_many :messages, -> { order(:created_at) }, dependent: :destroy
    has_many :tool_calls, through: :messages

    # –í–∞–ª–∏–¥–∞—Ü–∏–∏
    validates :title, presence: true
    validates :telegram_chat_id, uniqueness: true

    # –°–∫–æ–ø—ã –¥–ª—è —É–¥–æ–±–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    scope :active, -> { where('updated_at > ?', 1.day.ago) }
    scope :by_model, ->(model) { where(model: model) }

    # Callbacks
    after_create :set_default_title
    before_save :normalize_model_name

    private

    def set_default_title
      self.title ||= "–î–∏–∞–ª–æ–≥ –æ—Ç #{created_at.strftime('%d.%m.%Y %H:%M')}"
    end

    def normalize_model_name
      self.model = model&.downcase&.strip
    end
  end

  # –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è Valera Bot
  def context_for_user
    messages.last(20).map do |msg|
      {
        role: msg.role,
        content: msg.content,
        metadata: msg.metadata
      }
    end
  end

  def last_user_message
    messages.where(role: 'user').last
  end

  def conversation_summary
    "#{messages.count} —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç #{created_at.strftime('%d.%m.%Y')}"
  end

  def reset_context!
    messages.where.not(role: 'system').delete_all
    touch
  end
end
```

### Acts_as_message - —Ä–∞–±–æ—Ç–∞ —Å —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏

```ruby
# app/models/message.rb
class Message < ApplicationRecord
  include RubyLLM::Models::Message

  acts_as_message do
    belongs_to :chat
    has_many_attached :attachments
    has_many :tool_calls, dependent: :destroy

    # –í–∞–ª–∏–¥–∞—Ü–∏–∏
    validates :content, presence: true, unless: -> { has_attachments? }
    validates :role, inclusion: { in: %w[user system assistant tool] }

    # –°–∫–æ–ø—ã
    scope :user_messages, -> { where(role: 'user') }
    scope :assistant_messages, -> { where(role: 'assistant') }
    scope :with_errors, -> { where("metadata->>'error' IS NOT NULL") }
    scope :today, -> { where('created_at >= ?', Date.current) }

    # Callbacks
    after_create :update_chat_timestamp
    after_create :calculate_tokens_if_needed

    private

    def update_chat_timestamp
      chat.touch(:last_message_at)
    end

    def calculate_tokens_if_needed
      return if role == 'system' || content.blank?

      # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤
      CalculateTokensJob.perform_later(id)
    end
  end

  # –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è Valera Bot
  def has_attachments?
    attachments.attached?
  end

  def contains_photo?
    has_attachments? && attachments.any? { |att| att.content_type.start_with?('image/') }
  end

  def formatted_content_for_telegram
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Telegram (Markdown, escaping –∏ —Ç.–¥.)
    TelegramFormatter.format(content)
  end

  def extract_car_info
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–≤—Ç–æ–º–æ–±–∏–ª–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞
    CarInfoExtractor.extract(content)
  end

  def metadata_for_analysis
    metadata.merge({
      message_length: content.length,
      has_photo: contains_photo?,
      telegram_message_id: metadata['telegram_message_id'],
      created_at_russia: created_at.in_time_zone('Moscow')
    })
  end

  def has_attachments?
    attachments.attached?
  end
end
```

### Acts_as_tool_call - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

```ruby
# app/models/tool_call.rb
class ToolCall < ApplicationRecord
  include RubyLLM::Models::ToolCall

  acts_as_tool_call do
    belongs_to :message

    # –í–∞–ª–∏–¥–∞—Ü–∏–∏
    validates :name, presence: true
    validates :arguments, presence: true

    # –°–∫–æ–ø—ã
    scope :successful, -> { where(status: 'completed') }
    scope :failed, -> { where(status: 'failed') }
    scope :processing, -> { where(status: 'processing') }
    scope :by_tool, ->(tool_name) { where(name: tool_name) }

    # Callbacks
    before_create :set_processing_status
    after_update :notify_if_completed

    private

    def set_processing_status
      self.status ||= 'processing'
      self.started_at ||= Time.current
    end

    def notify_if_completed
      return unless saved_change_to_status(to: 'completed')

      self.completed_at = Time.current
      ToolCallCompletedNotificationJob.perform_later(id)
    end
  end

  # –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
  def duration
    return nil unless started_at && completed_at
    completed_at - started_at
  end

  def successful?
    status == 'completed'
  end

  def failed?
    status == 'failed'
  end

  def execute!
    update!(status: 'processing', started_at: Time.current)

    result = case name
             when 'diagnose_car_problem'
               CarDiagnosticService.diagnose(arguments)
             when 'estimate_repair_cost'
               CostEstimationService.estimate(arguments)
             when 'find_service_centers'
               ServiceCenterFinder.find(arguments)
             else
               { error: "Unknown tool: #{name}" }
             end

    update!(
      status: result[:error] ? 'failed' : 'completed',
      result: result,
      completed_at: Time.current
    )
  rescue => e
    update!(
      status: 'failed',
      result: { error: e.message, backtrace: e.backtrace.first(3) },
      completed_at: Time.current
    )
  end

  def parsed_arguments
    JSON.parse(arguments) rescue {}
  end
end
```

### –ú–∏–≥—Ä–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

```ruby
# db/migrate/001_create_chats.rb
class CreateChats < ActiveRecord::Migration[7.0]
  def change
    create_table :chats do |t|
      t.string :title
      t.string :telegram_chat_id, index: { unique: true }
      t.string :telegram_user_id
      t.string :model, default: 'gpt-4o-mini'
      t.decimal :temperature, precision: 3, scale: 2, default: 0.7
      t.integer :max_tokens, default: 2000
      t.json :metadata, default: {}
      t.datetime :last_message_at

      t.timestamps
    end

    add_index :chats, :telegram_chat_id, unique: true
    add_index :chats, :last_message_at
    add_index :chats, :model
  end
end

# db/migrate/002_create_messages.rb
class CreateMessages < ActiveRecord::Migration[7.0]
  def change
    create_table :messages do |t|
      t.references :chat, null: false, foreign_key: true, index: true
      t.string :role, null: false, index: true
      t.text :content
      t.json :metadata, default: {}
      t.string :model
      t.integer :tokens_used
      t.decimal :response_time, precision: 8, scale: 3
      t.string :telegram_message_id
      t.datetime :processed_at

      t.timestamps
    end

    add_index :messages, [:chat_id, :created_at]
    add_index :messages, :role
    add_index :messages, :telegram_message_id
  end
end

# db/migrate/003_create_tool_calls.rb
class CreateToolCalls < ActiveRecord::Migration[7.0]
  def change
    create_table :tool_calls do |t|
      t.references :message, null: false, foreign_key: true, index: true
      t.string :name, null: false, index: true
      t.json :arguments, null: false
      t.json :result
      t.string :status, default: 'processing', index: true
      t.datetime :started_at
      t.datetime :completed_at
      t.text :error_message

      t.timestamps
    end

    add_index :tool_calls, [:message_id, :name]
    add_index :tool_calls, :status
    add_index :tool_calls, :name
  end
end

# db/migrate/004_add_embeddings_to_messages.rb
class AddEmbeddingsToMessages < ActiveRecord::Migration[7.0]
  def change
    add_column :messages, :embedding, :vector, limit: 1536 # For text-embedding-3-small
    add_index :messages, :embedding, using: :cosine
  end
end
```

### –ú–æ–¥–µ–ª—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ LLM –º–æ–¥–µ–ª—è—Ö

```ruby
# app/models/llm_model.rb
class LLMModel < ApplicationRecord
  validates :model_id, presence: true, uniqueness: true
  validates :name, presence: true
  validates :provider, presence: true
  validates :context_window, numericality: { greater_than: 0 }
  validates :max_output_tokens, numericality: { greater_than: 0 }

  # –°–∫–æ–ø—ã –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞
  scope :openai, -> { where(provider: 'openai') }
  scope :anthropic, -> { where(provider: 'anthropic') }
  scope :vision_capable, -> { where("capabilities @> ?", ['vision'].to_json) }
  scope :cheap, -> { where('input_price < ?', 0.002) }
  scope :fast, -> { where('max_output_tokens > ?', 1000) }

  # –ú–µ—Ç–æ–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏
  def self.refresh_from_api!
    RubyLLM.models.each do |model|
      find_or_initialize_by(model_id: model.id).tap do |db_model|
        db_model.update!(
          name: model.name,
          provider: model.provider.to_s,
          family: model.family,
          context_window: model.context_window,
          max_output_tokens: model.max_output_tokens,
          modalities: model.modalities,
          capabilities: model.capabilities,
          input_price: model.pricing[:input],
          output_price: model.pricing[:output],
          metadata: model.metadata
        )
      end
    end
  end

  def supports_vision?
    capabilities.include?('vision')
  end

  def supports_tools?
    capabilities.include?('tools')
  end

  def cost_per_1k_tokens(input: true)
    price = input ? input_price : output_price
    (price * 1000).round(6)
  end

  def estimate_cost(input_tokens:, output_tokens:)
    (input_tokens * input_price + output_tokens * output_price).round(8)
  end

  def recommended_for_valera?
    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è Valera Bot
    %w[gpt-4o-mini gpt-4o claude-3-haiku].include?(model_id)
  end
end
```


## üõ†Ô∏è –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è Valera Bot

### 1. Streaming –æ—Ç–≤–µ—Ç—ã –¥–ª—è real-time –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è

```ruby
# app/services/valera_streaming_service.rb
class ValeraStreamingService
  def self.stream_consultation(chat, user_message, telegram_client)
    # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
    assistant_message = chat.messages.create!(
      role: 'assistant',
      content: '',
      model: chat.model || 'gpt-4o-mini',
      metadata: { streaming: true, started_at: Time.current }
    )

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º "–ø–µ—á–∞—Ç–∞–µ—Ç..." —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    telegram_client.send_chat_action(chat_id: chat.telegram_chat_id, action: 'typing')

    # Streaming –∑–∞–ø—Ä–æ—Å –∫ LLM
    RubyLLM.chat(
      model: chat.model || 'gpt-4o-mini',
      messages: chat.context_messages + [
        { role: 'user', content: user_message.content }
      ],
      stream: proc do |chunk|
        content_delta = extract_content(chunk)
        next if content_delta.blank?

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        assistant_message.content += content_delta
        assistant_message.save!

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º chunk –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (–µ—Å–ª–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ)
        if chunk_should_be_sent?(content_delta)
          telegram_client.send_message(
            chat_id: chat.telegram_chat_id,
            text: format_streaming_chunk(content_delta),
            parse_mode: 'Markdown'
          )
        end
      end
    )

    # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    assistant_message.metadata[:completed_at] = Time.current
    assistant_message.save!

    assistant_message
  end

  private

  def self.extract_content(chunk)
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞ API
    chunk.dig('choices', 0, 'delta', 'content')
  end

  def self.chunk_should_be_sent?(content)
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–º—ã—Å–ª–æ–≤—ã–µ —á–∞—Å—Ç–∏
    content.match?(/[\.\!\?\,\;\:]\s*$/)
  end

  def self.format_streaming_chunk(chunk)
    chunk.strip
  end
end
```

### 2. Embeddings –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫

```ruby
# app/services/embedding_service.rb
class EmbeddingService
  def self.create_for_message(message)
    return if message.role == 'tool' || message.content.blank?

    embedding_vector = RubyLLM.client.create_embedding(
      model: 'text-embedding-3-small',
      input: message.content
    ).dig('data', 0, 'embedding')

    message.update!(embedding: embedding_vector)
  rescue => e
    Rails.logger.error "Failed to create embedding for message #{message.id}: #{e.message}"
  end

  def self.find_similar_car_problems(query, limit: 5)
    query_embedding = RubyLLM.client.create_embedding(
      model: 'text-embedding-3-small',
      input: query
    ).dig('data', 0, 'embedding')

    # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏
    Message.joins(:chat)
           .where(role: 'user')
           .where("content ILIKE ? OR content ILIKE ? OR content ILIKE ?",
                  '%–ø—Ä–æ–±–ª–µ–º%', '%–Ω–µ–∏—Å–ø—Ä–∞–≤–Ω%', '%—Å–ª–æ–º–∞–ª%')
           .where.not(embedding: nil)
           .select("*, embedding <=> ? as distance", query_embedding)
           .order("distance ASC")
           .limit(limit)
  end

  def self.search_repair_cases(symptoms, car_make: nil)
    query = symptoms.join(' ')
    if car_make.present?
      query += " #{car_make}"
    end

    query_embedding = RubyLLM.client.create_embedding(
      model: 'text-embedding-3-small',
      input: query
    ).dig('data', 0, 'embedding')

    # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–µ–π—Å–æ–≤ —Ä–µ–º–æ–Ω—Ç–∞
    Message.joins(:chat)
           .where(role: 'assistant')
           .where("content ILIKE ANY(ARRAY[?])",
                  ['%—Ä–µ–º–æ–Ω—Ç%', '%–∑–∞–º–µ–Ω–∞%', '%–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫%'])
           .where.not(embedding: nil)
           .select("*, embedding <=> ? as distance", query_embedding)
           .order("distance ASC")
           .limit(10)
  end
end
```

### 3. –†–∞–±–æ—Ç–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (Vision API)

```ruby
# app/services/vision_analysis_service.rb
class VisionAnalysisService
  def self.analyze_car_photo(image_path, user_question)
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
    image_data = File.read(image_path)
    base64_image = Base64.strict_encode64(image_data)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º MIME —Ç–∏–ø
    mime_type = MIME::Types.type_for(image_path).first.content_type

    # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    response = RubyLLM.chat(
      model: 'gpt-4o', # –ú–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π vision
      messages: [
        {
          role: 'system',
          content: '–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–º—É —Ä–µ–º–æ–Ω—Ç—É —Å 20-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–æ—Ç–æ –∏ –¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.'
        },
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: "#{user_question}\n\n–û–ø–∏—à–∏ –¥–µ—Ç–∞–ª—å–Ω–æ, —á—Ç–æ —Ç—ã –≤–∏–¥–∏—à—å –Ω–∞ —Ñ–æ—Ç–æ, –∫–∞–∫–∏–µ —ç—Ç–æ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏ –∏ –∫–∞–∫ –∏—Ö –º–æ–∂–Ω–æ —É—Å—Ç—Ä–∞–Ω–∏—Ç—å."
            },
            {
              type: 'image_url',
              image_url: {
                url: "data:#{mime_type};base64,#{base64_image}"
              }
            }
          ]
        }
      ],
      max_tokens: 1000
    )

    response.content
  end

  def self.extract_damage_info(photo_path)
    prompt = <<~PROMPT
      –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ —Ñ–æ—Ç–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏:

      1. –ö–∞–∫–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è –≤–∏–¥–Ω—ã?
      2. –°—Ç–µ–ø–µ–Ω—å —Ç—è–∂–µ—Å—Ç–∏ (–Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ/—Å—Ä–µ–¥–Ω–∏–µ/—Ç—è–∂–µ–ª—ã–µ)
      3. –ö–∞–∫–∏–µ –¥–µ—Ç–∞–ª–∏ —Ç—Ä–µ–±—É—é—Ç –∑–∞–º–µ–Ω—ã?
      4. –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞ –≤ —Ä—É–±–ª—è—Ö
      5. –°—Ä–æ—á–Ω–æ –ª–∏ —ç—Ç–æ –Ω—É–∂–Ω–æ —Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å?

      –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
      {
        "damages": ["—Å–ø–∏—Å–æ–∫ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π"],
        "severity": "low|medium|high",
        "parts_to_replace": ["–¥–µ—Ç–∞–ª–∏ –¥–ª—è –∑–∞–º–µ–Ω—ã"],
        "estimated_cost_rub": —á–∏—Å–ª–æ,
        "urgency": "low|medium|high",
        "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–µ–º–æ–Ω—Ç—É"]
      }
    PROMPT

    analysis = analyze_car_photo(photo_path, prompt)

    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
    JSON.parse(analysis) rescue format_text_response(analysis)
  end

  private

  def self.format_text_response(text)
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –≤ JSON
    {
      "damages" => extract_list(text, "–ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è"),
      "severity" => extract_severity(text),
      "parts_to_replace" => extract_list(text, "–∑–∞–º–µ–Ω"),
      "estimated_cost_rub" => extract_cost(text),
      "urgency" => extract_urgency(text),
      "recommendations" => extract_list(text, "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è")
    }
  end
end
```

### 4. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```ruby
# app/services/reliable_llm_service.rb
class ReliableLlmService
  MAX_RETRIES = 3
  BASE_DELAY = 1
  MAX_DELAY = 30

  def self.chat_with_fallbacks(chat, user_message)
    with_comprehensive_retry do
      response = attempt_primary_model(chat, user_message)
      return response if response.success?

      # Fallback –Ω–∞ –±–æ–ª–µ–µ –¥–µ—à–µ–≤—É—é –º–æ–¥–µ–ª—å
      response = attempt_fallback_model(chat, user_message)
      return response if response.success?

      # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ —Å —É–ø—Ä–æ—â–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
      attempt_with_simplified_context(chat, user_message)
    end
  rescue => e
    handle_final_error(e, chat, user_message)
  end

  private

  def self.with_comprehensive_retry
    attempts = 0

    begin
      attempts += 1
      result = yield

      # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
      attempts = 0
      result

    rescue => error
      if attempts < MAX_RETRIES
        # Exponential backoff —Å jitter
        delay = calculate_delay(attempts)
        Rails.logger.warn "LLM retry #{attempts}/#{MAX_RETRIES} after #{delay}s: #{error.message}"

        sleep(delay)
        retry
      else
        Rails.logger.error "All LLM retry attempts failed: #{error.message}"
        raise error
      end
    end
  end

  def self.calculate_delay(attempt)
    base_delay = BASE_DELAY * (2 ** (attempt - 1))
    jitter = rand(0.1..0.3) * base_delay
    [base_delay + jitter, MAX_DELAY].min
  end

  def self.attempt_primary_model(chat, user_message)
    try_with_model(chat, user_message, chat.model || 'gpt-4o-mini')
  end

  def self.attempt_fallback_model(chat, user_message)
    fallback_models = ['gpt-3.5-turbo', 'claude-3-haiku']
    fallback_models.each do |model|
      response = try_with_model(chat, user_message, model)
      return response if response.success?
    end
    nil
  end

  def self.attempt_with_simplified_context(chat, user_message)
    simplified_context = [
      chat.context_messages.first, # System message
      chat.context_messages.last(3) # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è
    ].flatten

    RubyLLM.chat(
      model: 'gpt-3.5-turbo',
      messages: simplified_context + [
        { role: 'user', content: user_message.content }
      ]
    )
  end

  def self.try_with_model(chat, user_message, model)
    RubyLLM.chat(
      model: model,
      messages: chat.context_messages + [
        { role: 'user', content: user_message.content }
      ]
    )
  rescue => e
    Rails.logger.warn "Failed to get response from #{model}: #{e.message}"
    OpenStruct.new(success?: false, error: e.message)
  end

  def self.handle_final_error(error, chat, user_message)
    Rails.logger.error "LLM service final error: #{error.message}"

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    chat.messages.create!(
      role: 'assistant',
      content: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.',
      metadata: {
        error: error.message,
        error_type: error.class.name,
        failed_at: Time.current
      }
    )

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É
    AdminNotifier.llm_error(error, chat, user_message)

    OpenStruct.new(
      success?: false,
      error: error.message,
      fallback_message: '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
    )
  end
end
```

### 5. Tool/Function Calling –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏

```ruby
# app/services/valera_tools_service.rb
class ValeraToolsService
  # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º
  def self.diagnose_car_problem(arguments)
    car_make = arguments['car_make']
    symptoms = arguments['symptoms']
    additional_info = arguments['additional_info']

    # –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–∏–º–ø—Ç–æ–º–æ–≤ –∏ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–∏—á–∏–Ω
    diagnostic_db = load_diagnostic_database

    matches = []
    symptoms.each do |symptom|
      symptom_key = symptom.downcase.gsub(/\s+/, '_')
      if diagnostic_db[symptom_key]
        matches.concat(diagnostic_db[symptom_key])
      end
    end

    # –£—Å—Ç—Ä–∞–Ω—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    unique_matches = matches.uniq.sort_by { |m| -m[:probability] }

    {
      success: true,
      diagnosis: unique_matches.first(3),
      confidence: calculate_confidence(unique_matches, symptoms),
      recommendations: generate_recommendations(unique_matches, car_make),
      estimated_costs: estimate_costs_by_symptoms(unique_matches, car_make)
    }
  end

  # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ä–µ–º–æ–Ω—Ç–∞
  def self.estimate_repair_cost(arguments)
    repair_type = arguments['repair_type']
    car_make = arguments['car_make']
    car_model = arguments['car_model']
    urgency = arguments['urgency'] || 'medium'
    region = arguments['region'] || 'moscow'

    # –ë–∞–∑–∞ —Ü–µ–Ω –Ω–∞ —Ä–µ–º–æ–Ω—Ç
    price_db = load_price_database

    base_price = price_db.dig(repair_type.downcase, 'base_price') || 15000
    make_multiplier = price_db.dig('car_multipliers', car_make.downcase) || 1.0
    urgency_multiplier = { 'low' => 0.8, 'medium' => 1.0, 'high' => 1.3 }[urgency] || 1.0
    region_multiplier = { 'moscow' => 1.2, 'spb' => 1.1, 'other' => 1.0 }[region] || 1.0

    estimated_cost = (base_price * make_multiplier * urgency_multiplier * region_multiplier).round

    {
      success: true,
      repair_type: repair_type,
      car_make: car_make,
      car_model: car_model,
      urgency: urgency,
      region: region,
      estimated_cost: estimated_cost,
      currency: 'RUB',
      price_range: {
        min: (estimated_cost * 0.8).round,
        max: (estimated_cost * 1.3).round
      },
      time_required: estimate_repair_time(repair_type),
      confidence: 'high'
    }
  end

  # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–æ–≤
  def self.find_service_centers(arguments)
    repair_type = arguments['repair_type']
    location = arguments['location'] || '–ú–æ—Å–∫–≤–∞'
    radius = arguments['radius'] || 10

    # –ò–º–∏—Ç–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –ø–æ –±–∞–∑–µ –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å–æ–≤
    service_centers = [
      {
        name: '–ê–≤—Ç–æ—Å–µ—Ä–≤–∏—Å "–ú–∞—Å—Ç–µ—Ä-–ê–≤—Ç–æ"',
        address: "#{location}, —É–ª. –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω–∞—è, 15",
        phone: '+7 (495) 123-45-67',
        rating: 4.8,
        specialties: ['–¥–≤–∏–≥–∞—Ç–µ–ª—å', '—Ç–æ—Ä–º–æ–∑–∞', '–ø–æ–¥–≤–µ—Å–∫–∞'],
        distance_km: rand(1.0..radius).round(1),
        estimated_wait_time: "#{rand(1..3)} –¥–Ω—è",
        price_level: 'medium'
      },
      {
        name: '–¢–µ—Ö—Ü–µ–Ω—Ç—Ä "–ê–≤—Ç–æ-–ü–ª—é—Å"',
        address: "#{location}, –ø—Ä. –õ–µ–Ω–∏–Ω–∞, 42",
        phone: '+7 (495) 987-65-43',
        rating: 4.6,
        specialties: ['—Ç—Ä–∞–Ω—Å–º–∏—Å—Å–∏—è', '—ç–ª–µ–∫—Ç—Ä–∏–∫–∞', '–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞'],
        distance_km: rand(1.0..radius).round(1),
        estimated_wait_time: "#{rand(1..2)} –¥–Ω—è",
        price_level: 'low'
      }
    ]

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    filtered_centers = service_centers.select do |center|
      center[:specialties].any? { |spec| spec.include?(repair_type) }
    end

    {
      success: true,
      repair_type: repair_type,
      location: location,
      service_centers: filtered_centers.sort_by { |c| c[:distance_km] },
      total_found: filtered_centers.length,
      search_radius: radius
    }
  end

  private

  def self.load_diagnostic_database
    {
      '—Å—Ç—É–∫_–ø—Ä–∏_—Ç–æ—Ä–º–æ–∂–µ–Ω–∏–∏' => [
        { problem: '–ò–∑–Ω–æ—Å —Ç–æ—Ä–º–æ–∑–Ω—ã—Ö –∫–æ–ª–æ–¥–æ–∫', probability: 0.7, urgency: 'high' },
        { problem: '–î–µ—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç–æ—Ä–º–æ–∑–Ω—ã—Ö –¥–∏—Å–∫–æ–≤', probability: 0.5, urgency: 'medium' },
        { problem: '–ò–∑–Ω–æ—Å —Å—Ç—É–ø–∏—á–Ω—ã—Ö –ø–æ–¥—à–∏–ø–Ω–∏–∫–æ–≤', probability: 0.3, urgency: 'medium' }
      ],
      '–¥–≤–∏–≥–∞—Ç–µ–ª—å_–Ω–µ_–∑–∞–≤–æ–¥–∏—Ç—Å—è' => [
        { problem: '–†–∞–∑—Ä—è–∂–µ–Ω–Ω—ã–π –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä', probability: 0.6, urgency: 'low' },
        { problem: '–ü—Ä–æ–±–ª–µ–º–∞ —Å–æ —Å—Ç–∞—Ä—Ç–µ—Ä–æ–º', probability: 0.4, urgency: 'medium' },
        { problem: '–ó–∞—Å–æ—Ä–∏–ª—Å—è —Ç–æ–ø–ª–∏–≤–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä', probability: 0.3, urgency: 'medium' }
      ],
      '–ø–æ–≤—ã—à–µ–Ω–Ω—ã–π_—Ä–∞—Å—Ö–æ–¥_–º–∞—Å–ª–∞' => [
        { problem: '–ò–∑–Ω–æ—Å –º–∞—Å–ª–æ—Å—ä–µ–º–Ω—ã—Ö –∫–æ–ª–ø–∞—á–∫–æ–≤', probability: 0.5, urgency: 'low' },
        { problem: '–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–ª–∞–ø–∞–Ω–Ω–æ–π –∫—Ä—ã—à–∫–∏', probability: 0.4, urgency: 'medium' },
        { problem: '–ò–∑–Ω–æ—Å –ø–æ—Ä—à–Ω–µ–≤—ã—Ö –∫–æ–ª–µ—Ü', probability: 0.2, urgency: 'high' }
      ]
    }
  end

  def self.load_price_database
    {
      '—Ç–æ—Ä–º–æ–∑–∞' => {
        'base_price' => 8000,
        'parts_cost' => 5000,
        'labor_hours' => 2
      },
      '–ø–æ–¥–≤–µ—Å–∫–∞' => {
        'base_price' => 12000,
        'parts_cost' => 8000,
        'labor_hours' => 3
      },
      '–¥–≤–∏–≥–∞—Ç–µ–ª—å' => {
        'base_price' => 25000,
        'parts_cost' => 18000,
        'labor_hours' => 6
      },
      'car_multipliers' => {
        'toyota' => 1.0,
        'bmw' => 1.5,
        'mercedes' => 1.6,
        'audi' => 1.4,
        'volkswagen' => 1.1,
        'kia' => 0.9,
        'hyundai' => 0.9
      }
    }
  end

  def self.calculate_confidence(matches, symptoms)
    return 'low' if matches.empty?
    return 'high' if matches.length >= symptoms.length
    'medium'
  end

  def self.generate_recommendations(matches, car_make)
    recommendations = []

    matches.each do |match|
      case match[:problem]
      when '–ò–∑–Ω–æ—Å —Ç–æ—Ä–º–æ–∑–Ω—ã—Ö –∫–æ–ª–æ–¥–æ–∫'
        recommendations << "–ó–∞–º–µ–Ω–∏—Ç–µ —Ç–æ—Ä–º–æ–∑–Ω—ã–µ –∫–æ–ª–æ–¥–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç–æ–º –Ω–∞ –æ–±–µ–∏—Ö –∫–æ–ª–µ—Å–∞—Ö"
      when '–†–∞–∑—Ä—è–∂–µ–Ω–Ω—ã–π –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä'
        recommendations << "–ó–∞—Ä—è–¥–∏—Ç–µ –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –µ–≥–æ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å"
      when '–ò–∑–Ω–æ—Å –º–∞—Å–ª–æ—Å—ä–µ–º–Ω—ã—Ö –∫–æ–ª–ø–∞—á–∫–æ–≤'
        recommendations << "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–º–µ–Ω–∞ –º–∞—Å–ª–æ—Å—ä–µ–º–Ω—ã—Ö –∫–æ–ª–ø–∞—á–∫–æ–≤"
      end
    end

    recommendations.uniq.first(3)
  end

  def self.estimate_costs_by_symptoms(matches, car_make)
    matches.first(3).map do |match|
      {
        problem: match[:problem],
        estimated_cost: estimate_single_repair_cost(match[:problem], car_make),
        urgency: match[:urgency]
      }
    end
  end

  def self.estimate_single_repair_cost(problem, car_make)
    base_costs = {
      '–ò–∑–Ω–æ—Å —Ç–æ—Ä–º–æ–∑–Ω—ã—Ö –∫–æ–ª–æ–¥–æ–∫' => 8000,
      '–†–∞–∑—Ä—è–∂–µ–Ω–Ω—ã–π –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä' => 5000,
      '–ò–∑–Ω–æ—Å –º–∞—Å–ª–æ—Å—ä–µ–º–Ω—ã—Ö –∫–æ–ª–ø–∞—á–∫–æ–≤' => 15000,
      '–ü—Ä–æ–∫–ª–∞–¥–∫–∞ –∫–ª–∞–ø–∞–Ω–Ω–æ–π –∫—Ä—ã—à–∫–∏' => 10000
    }

    make_multiplier = { 'bmw' => 1.5, 'mercedes' => 1.6, 'audi' => 1.4 }[car_make&.downcase] || 1.0

    (base_costs[problem] || 12000) * make_multiplier
  end

  def self.estimate_repair_time(repair_type)
    time_db = {
      '—Ç–æ—Ä–º–æ–∑–∞' => '2-3 —á–∞—Å–∞',
      '–ø–æ–¥–≤–µ—Å–∫–∞' => '4-6 —á–∞—Å–æ–≤',
      '–¥–≤–∏–≥–∞—Ç–µ–ª—å' => '1-3 –¥–Ω—è',
      '—Ç—Ä–∞–Ω—Å–º–∏—Å—Å–∏—è' => '2-4 –¥–Ω—è',
      '–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞' => '1-2 —á–∞—Å–∞'
    }

    time_db[repair_type.downcase] || '2-4 —á–∞—Å–∞'
  end
end
```

## üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è Valera Bot

### 1. –£–º–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤

```ruby
# app/services/valera_cache_service.rb
class ValeraCacheService
  CACHE_VERSION = 'v1'
  DEFAULT_TTL = 2.hours

  def self.get_cached_response(chat, user_message)
    cache_key = generate_cache_key(chat, user_message)

    Rails.cache.fetch(cache_key, expires_in: calculate_ttl(user_message)) do
      response = generate_response(chat, user_message)

      {
        content: response.content,
        model: response.model,
        tokens_used: response.usage&.total_tokens,
        cached_at: Time.current,
        cache_version: CACHE_VERSION
      }
    end
  end

  def self.invalidate_cache(chat_id)
    pattern = "valera_llm:chat_#{chat_id}:*"
    Rails.cache.delete_matched(pattern)
  end

  def self.cache_hit_rate
    total_requests = Rails.cache.read('valera_llm:stats:total_requests') || 0
    cache_hits = Rails.cache.read('valera_llm:stats:cache_hits') || 0

    return 0 if total_requests.zero?
    (cache_hits.to_f / total_requests * 100).round(2)
  end

  private

  def self.generate_cache_key(chat, user_message)
    context_hash = Digest::MD5.hexdigest(
      chat.context_messages.last(5)
          .map { |m| "#{m[:role]}:#{m[:content]}" }
          .join('|')
    )

    message_hash = Digest::MD5.hexdigest(normalize_message(user_message.content))
    model_hash = Digest::MD5.hexdigest(chat.model || 'gpt-4o-mini')

    "valera_llm:chat_#{chat.id}:#{model_hash}:#{context_hash}:#{message_hash}:#{CACHE_VERSION}"
  end

  def self.normalize_message(content)
    content.downcase.gsub(/[^\w\s]/, '').gsub(/\s+/, ' ').strip
  end

  def self.calculate_ttl(user_message)
    if user_message.content.downcase.include?('—Ü–µ–Ω–∞') ||
       user_message.content.downcase.include?('—Å—Ç–æ–∏–º–æ—Å—Ç—å')
      24.hours
    elsif user_message.content.downcase.include?('—Å—Ä–æ—á–Ω–æ')
      30.minutes
    else
      DEFAULT_TTL
    end
  end
end
```

### 2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

```ruby
# app/services/token_optimizer_service.rb
class TokenOptimizerService
  MAX_CONTEXT_TOKENS = 7000
  SYSTEM_TOKENS = 200

  def self.optimize_context(chat, user_message)
    original_context = chat.context_messages

    if estimate_tokens(original_context + [{ role: 'user', content: user_message.content }]) <= MAX_CONTEXT_TOKENS
      return original_context
    end

    optimized_context = build_optimized_context(original_context, user_message)
    Rails.logger.info "Context optimized: #{original_context.length} -> #{optimized_context.length} messages"
    optimized_context
  end

  def self.estimate_tokens(messages)
    total_chars = messages.sum { |msg| msg[:content].to_s.length }
    (total_chars / 4.0).ceil + SYSTEM_TOKENS
  end

  def self.build_optimized_context(original_context, user_message)
    system_message = original_context.find { |m| m[:role] == 'system' }
    optimized = [system_message].compact

    recent_messages = original_context.reject { |m| m[:role] == 'system' }.last(6)
    optimized.concat(recent_messages)

    while estimate_tokens(optimized + [{ role: 'user', content: user_message.content }]) > MAX_CONTEXT_TOKENS
      break if optimized.length <= 2
      removed = optimized.shift if optimized.first[:role] != 'system'
      break unless removed
    end

    optimized
  end
end
```

## üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ruby_llm –¥–ª—è Valera Bot

### 1. Unit —Ç–µ—Å—Ç—ã –¥–ª—è —Å–µ—Ä–≤–∏—Å–æ–≤

```ruby
# test/services/valera_tools_service_test.rb
class ValeraToolsServiceTest < ActiveSupport::TestCase
  test "should diagnose car problem correctly" do
    arguments = {
      'car_make' => 'Toyota',
      'symptoms' => ['—Å—Ç—É–∫ –ø—Ä–∏ —Ç–æ—Ä–º–æ–∂–µ–Ω–∏–∏', '–≤–∏—Ä–∞—Ü–∏—è —Ä—É–ª—è'],
      'additional_info' => '–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ 60 –∫–º/—á'
    }

    result = ValeraToolsService.diagnose_car_problem(arguments)

    assert result[:success]
    assert result[:diagnosis].any?
    assert_includes result[:diagnosis].map { |d| d[:problem] }, '–ò–∑–Ω–æ—Å —Ç–æ—Ä–º–æ–∑–Ω—ã—Ö –∫–æ–ª–æ–¥–æ–∫'
    assert_equal 'medium', result[:confidence]
  end

  test "should estimate repair cost with multipliers" do
    arguments = {
      'repair_type' => '—Ç–æ—Ä–º–æ–∑–∞',
      'car_make' => 'BMW',
      'urgency' => 'high',
      'region' => 'moscow'
    }

    result = ValeraToolsService.estimate_repair_cost(arguments)

    assert result[:success]
    assert result[:estimated_cost] > 8000
    assert_equal 'RUB', result[:currency]
  end
end
```

### 2. Mock –∏ Stub —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```ruby
# test/support/llm_test_helpers.rb
module LlmTestHelpers
  def mock_llm_response(content, tool_calls: [])
    response = OpenStruct.new(
      content: content,
      model: 'gpt-4o-mini',
      usage: OpenStruct.new(total_tokens: 150),
      tool_calls: tool_calls
    )

    RubyLLM::Chat.any_instance.stubs(:say).returns(response)
    response
  end

  def create_test_chat(**options)
    Chat.create!(
      title: options[:title] || 'Test Chat',
      telegram_chat_id: options[:telegram_chat_id] || '123456',
      model: options[:model] || 'gpt-4o-mini',
      temperature: options[:temperature] || 0.7,
      **options
    )
  end

  def create_user_message(chat, content)
    chat.messages.create!(
      role: 'user',
      content: content,
      metadata: { source: 'test' }
    )
  end
end

# test/test_helper.rb
class ActiveSupport::TestCase
  include LlmTestHelpers

  setup do
    RubyLLM::Chat.any_instance.stubs(:say).raises(
      StandardError.new("Real API calls disabled in tests")
    )
  end
end
```

## üéØ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Valera Bot

### 1. –ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ

```ruby
# app/services/valera_consultant_service.rb
class ValeraConsultantService
  SYSTEM_PROMPT = <<~PROMPT
    –¢—ã - –í–∞–ª–µ—Ä–∞, AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–º—É —Ä–µ–º–æ–Ω—Ç—É —Å 20-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º.

    –¢–≤–æ–∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
    1. –í—Å–µ–≥–¥–∞ —Å–ø—Ä–∞—à–∏–≤–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    2. –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∏ –æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å
    3. –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã
    4. –£—á–∏—Ç—ã–≤–∞–π —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ —Ä–µ–∞–ª–∏–∏ (–∫–∞—á–µ—Å—Ç–≤–æ –¥–æ—Ä–æ–≥, –∫–ª–∏–º–∞—Ç, –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∑–∞–ø—á–∞—Å—Ç–µ–π)
    5. –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –æ–ø–∞—Å–Ω–∞—è - —Å—Ä–∞–∑—É —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º

    –°—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è:
    - –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã–π —è–∑—ã–∫
    - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã (–ø—É–Ω–∫—Ç—ã, —Å–ø–∏—Å–∫–∏)
    - –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥
  PROMPT

  def self.consult(chat, user_input)
    ensure_system_prompt(chat)

    if emergency_situation?(user_input)
      handle_emergency(chat, user_input)
      return
    end

    if has_photo?(user_input)
      handle_photo_request(chat, user_input)
      return
    end

    handle_standard_consultation(chat, user_input)
  end

  private

  def self.emergency_situation?(input)
    emergency_keywords = %w[
      –¥—ã–º –¥—ã–º–∏—Ç—Å—è –ø–æ–∂–∞—Ä –≥–æ—Ä–∏—Ç
      –Ω–µ_—Ç–æ—Ä–º–æ–∑–∏—Ç –æ—Ç–∫–∞–∑–∞–ª–∏_—Ç–æ—Ä–º–æ–∑–∞
      –º–∞—Å–ª–æ_—Ç–µ—á–µ—Ç –ª—É–∂–∞_–ø–æ–¥_–º–∞—à–∏–Ω–æ–π
      –¥–≤–∏–≥–∞—Ç–µ–ª—å_–∑–∞–≥–ª–æ—Ö –æ—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è
      –∞–≤–∞—Ä–∏—è –¥—Ç–ø
    ]

    emergency_keywords.any? { |keyword| input.downcase.include?(keyword) }
  end

  def self.handle_emergency(chat, user_input)
    emergency_response = <<~RESPONSE
      üö® **–û–ü–ê–°–ù–ê–Ø –°–ò–¢–£–ê–¶–ò–Ø!** –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –ø—Ä–∏–º–∏—Ç–µ –º–µ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏:

      **1. –û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ—Å—å:**
      - –°—ä–µ–∑–∂–∞–π—Ç–µ –Ω–∞ –æ–±–æ—á–∏–Ω—É –∏–ª–∏ –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –º–µ—Å—Ç–æ
      - –í–∫–ª—é—á–∏—Ç–µ –∞–≤–∞—Ä–∏–π–Ω—É—é —Å–∏–≥–Ω–∞–ª–∏–∑–∞—Ü–∏—é
      - –ó–∞–≥–ª—É—à–∏—Ç–µ –¥–≤–∏–≥–∞—Ç–µ–ª—å

      **2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:**
      - –ï—Å–ª–∏ –µ—Å—Ç—å –¥—ã–º –∏–ª–∏ –∑–∞–ø–∞—Ö –≥–∞—Ä–∏ - –≤—ã–π–¥–∏—Ç–µ –∏–∑ –º–∞—à–∏–Ω—ã
      - –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–Ω–∞–∫ –∞–≤–∞—Ä–∏–π–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
      - –û—Ç–æ–π–¥–∏—Ç–µ –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ

      **3. –í—ã–∑–æ–≤–∏—Ç–µ –ø–æ–º–æ—â—å:**
      - –ï—Å–ª–∏ –µ—Å—Ç—å —É–≥—Ä–æ–∑–∞ –∂–∏–∑–Ω–∏: 112 –∏–ª–∏ 103
      - –≠–≤–∞–∫—É–∞—Ç–æ—Ä: –ø–æ–∏—â–∏—Ç–µ –º–µ—Å—Ç–Ω—ã–π –Ω–æ–º–µ—Ä –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
      - –ù–µ –ø—ã—Ç–∞–π—Ç–µ—Å—å –µ—Ö–∞—Ç—å –¥–∞–ª—å—à–µ!

      –û–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ, —è –ø–æ–º–æ–≥—É –æ—Ü–µ–Ω–∏—Ç—å —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å.
    RESPONSE

    chat.messages.create!(role: 'assistant', content: emergency_response)
  end

  def self.handle_standard_consultation(chat, user_input)
    tools = [
      diagnostic_tool_definition,
      cost_calculator_tool_definition,
      service_finder_tool_definition
    ]

    response = RubyLLM.chat(
      model: chat.model || 'gpt-4o-mini',
      messages: chat.context_messages + [
        { role: 'user', content: user_input.content }
      ],
      tools: tools,
      temperature: 0.3
    )

    assistant_message = chat.messages.create!(
      role: 'assistant',
      content: response.content,
      model: response.model
    )

    if response.respond_to?(:tool_calls) && response.tool_calls.any?
      process_tool_calls(response.tool_calls, chat, assistant_message)
    end
  end

  def self.diagnostic_tool_definition
    {
      name: 'diagnose_car_problem',
      description: '–î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ø–æ —Å–∏–º–ø—Ç–æ–º–∞–º',
      input_schema: {
        type: 'object',
        properties: {
          car_make: { type: 'string', description: '–ú–∞—Ä–∫–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è' },
          symptoms: {
            type: 'array',
            items: { type: 'string' },
            description: '–°–ø–∏—Å–æ–∫ —Å–∏–º–ø—Ç–æ–º–æ–≤'
          }
        },
        required: ['car_make', 'symptoms']
      }
    }
  end

  def self.cost_calculator_tool_definition
    {
      name: 'estimate_repair_cost',
      description: '–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ä–µ–º–æ–Ω—Ç–∞',
      input_schema: {
        type: 'object',
        properties: {
          repair_type: { type: 'string', description: '–¢–∏–ø —Ä–µ–º–æ–Ω—Ç–∞' },
          car_make: { type: 'string', description: '–ú–∞—Ä–∫–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª—è' },
          urgency: { type: 'string', enum: ['low', 'medium', 'high'] }
        },
        required: ['repair_type', 'car_make']
      }
    }
  end

  def self.service_finder_tool_definition
    {
      name: 'find_service_centers',
      description: '–ò—â–µ—Ç –∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å—ã –ø–æ–±–ª–∏–∑–æ—Å—Ç–∏',
      input_schema: {
        type: 'object',
        properties: {
          repair_type: { type: 'string', description: '–¢–∏–ø —Ä–µ–º–æ–Ω—Ç–∞' },
          location: { type: 'string', description: '–ì–æ—Ä–æ–¥ –∏–ª–∏ –∞–¥—Ä–µ—Å' }
        },
        required: ['repair_type']
      }
    }
  end
end
```

---

## üìã –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–≠—Ç–∞ **comprehensive –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è** –ø–æ ruby_llm gem –¥–ª—è **Valera Bot** –≤–∫–ª—é—á–∞–µ—Ç:

‚úÖ **–ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ API** gem –∏ –µ–≥–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
‚úÖ **Rails –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é** —Å acts_as –º–∞–∫—Ä–æ—Å–∞–º–∏
‚úÖ **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏**: streaming, embeddings, vision, tools
‚úÖ **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã** –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π —Ä–∞–±–æ—Ç—ã
‚úÖ **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é** –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
‚úÖ **–û–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫** –∏ retry –ª–æ–≥–∏–∫—É
‚úÖ **–ü–æ–ª–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã** –¥–ª—è –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
‚úÖ **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** unit, integration –∏ mocking
‚úÖ **–†–µ–∞–ª—å–Ω—ã–µ use cases** –¥–ª—è Valera Bot

**–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é** –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ Telegram –±–æ—Ç–∞ —Å AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–º—É —Ä–µ–º–æ–Ω—Ç—É! üöóüîß

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: [ruby_llm GitHub](https://github.com/oldmoe/ruby_llm)
- **API Reference**: —Å–º. ruby_llm API documentation
- **–ü—Ä–∏–º–µ—Ä—ã**: [examples/](./examples/) –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã**: [patterns.md](./patterns.md)
- **Telegram Bot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è**: [../telegram-bot/](../telegram-bot/)

**–î–ª—è Valera Bot team:** –≠—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è - –≤–∞—à –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ—Å—É—Ä—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ruby_llm gem. –û–±—Ä–∞—â–∞–π—Ç–µ—Å—å –∫ –Ω–µ–π –ø—Ä–∏ –ª—é–±–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.

